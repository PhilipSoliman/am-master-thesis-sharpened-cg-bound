\chapter{Introduction}\label{ch:introduction}
In this thesis we focus on a simple scalar diffusion problem. Let $\Omega\subset\mathbb{R}^d$ be a bounded domain with Lipschitz boundary $\partial\Omega$, $\mathcal{C}\in L^\infty(\Omega)$ be scalar field defined on $\Omega$ such that $0 < \mathcal{C}_{\min} \leq \mathcal{C}(x) \leq \mathcal{C}_{\max} < \infty$ for all $x\in\Omega$ and $f\in L^2(\Omega)$ be a source term, then we define
\begin{fancyprob}{High-contrast scalar elliptic problem: strong formulation}{elliptic_problem}
    Let $u_D\in H^2(\partial\Omega)$ be a Dirichlet boundary condition. Find $u\in H^2(\Omega)$ such that
    \begin{equation}
        \begin{aligned}
            -\nabla\cdot\left(\mathcal{C}\nabla u\right) & = f \quad \text{in } \Omega,           \\
            u                                       & = u_D \quad \text{on } \partial\Omega.
        \end{aligned}
        \label{eq:elliptic_problem}
    \end{equation}
\end{fancyprob}

In \cref{tab:high_contrast_examples} we give an overview of some real-world applications that can be modeled using \cref{prob:elliptic_problem}. These applications span a wide range of fields, including electronics, hydrogeology, biomechanics, materials science, and energy.
\input{../../tables/applications.tex}

The first step in solving \cref{prob:elliptic_problem} is to reformulate the problem in a way that reduces the regularity constraint on the solution $u\in H^2(\Omega)$ and not requiring to $\nabla\cdot\left(\mathcal{C}\nabla u\right)$ to exist pointwise. This leads to the weak formulation of the problem, which is obtained by multiplying \cref{eq:elliptic_problem} with a test function $v\in H^1_0(\Omega)$ and integrating over $\Omega$. The weak formulation is given by
\begin{fancyprob}{High-contrast scalar elliptic problem: weak formulation}{elliptic_problem_weak}
    Let $u_D\in H^1(\partial\Omega)$ be a Dirichlet boundary condition. Find $u\in V = \{u\in H^1(\Omega) | u_{\delta \Omega} = u_D\}$ such that $\forall v \in H^1_0(\Omega)$
    \begin{equation}
        \label{eq:galerkin}
        \int_\Omega \mathcal{C}\nabla u\cdot\nabla v\,dx = \int_\Omega f v\,dx.
    \end{equation}
\end{fancyprob}

To solve this problem numerically, we need to discretize the domain $\Omega$ and the solution space $V$. To that end we consider a triangulation $\mathcal{T}$ of the domain $\Omega$ with the $\mathcal{N}$ the set of degrees of freedom (DOFs). Then, we pick a finite dimensional subspace of $V$, $V_h$ spanned by a set of basis functions $\phi_i$ defined locally on each of the elements $\tau \in \mathcal{T}$
\begin{equation*}
  V_h = \text{span}\{\phi_i\}_{i=1}^{n},
\end{equation*}
where $n = |\mathcal{N}|$. This leads to the discretized weak formulation
\begin{fancyprob}{High-contrast scalar elliptic problem: discretized weak formulation}{elliptic_problem_discretized}
    Let $u_D\in H^1(\partial\Omega)$ be a Dirichlet boundary condition. Find $u_h\in V_h$ such that $\forall v_h \in V_{h,0} = V_h\cap H^1_0(\Omega)$
    \begin{equation}
        a(u_h, v_h) = \int_\Omega \mathcal{C}\nabla u_h\cdot\nabla v_h\,dx = \int_\Omega f v_h \,dx = (f, v_h),
        \label{eq:discretized_problem}
    \end{equation}
    where $a(u_h, v_h)$ is the bilinear form and $(f, v_h)$ is the linear form. Equation (\ref{eq:discretized_problem}) gives rise to the following system of equations
    \begin{equation*}
        A\mathbf{u} = \mathbf{b}, \quad A_{ij} = a(\phi_i, \phi_j), \ b_i = (f, \phi_i) \quad \forall i,j\in\mathcal{N},
    \end{equation*}
    where $A\in\mathbb{R}^{n \times n}$ is the (by construction) symmetric stiffness matrix, $\mathbf{u}\in\mathbb{R}^{n}$ the solution vector with components $u_i$ and $\mathbf{b}\in\mathbb{R}^{n}$ the load vector. The load vector $\mathbf{b}$ is constructed from the source term $f$ and the boundary conditions. The approximate solution $u_h$ is constructed from the basis functions $\phi_i$ as
    \begin{equation*}
        u_h = \sum_{i\in\mathcal{N}} u_i \phi_i.
    \end{equation*}
\end{fancyprob}
Note that the bilinear form $a$ in \cref{prob:elliptic_problem_discretized} is coercive, meaning that for all $0\neq w\in H^1_0(\Omega)$ we have
\begin{equation*}
  a(w,w) = \int_\Omega \mathcal{C} \nabla w\cdot\nabla w\,dx = \int_\Omega \mathcal{C} |\nabla w|^2\,dx = \mathcal{C}_{\text{min}} \|\nabla w\|_{L_2(\Omega)}^2> \frac{\mathcal{C}_{\text{min}}}{C_p^2}\|\nabla w\|_{H^1_0(\Omega)}^2 \geq 0,
\end{equation*}
since $\mathcal{C}_{\text{min}}>0$ and with $C_p$ the PoincarÃ© constant. Moreover, for 
\[
    w = \sum_{i\in\mathcal{N}} w_i \phi_i \quad \text{with} \quad \mathbf{w} = (w_1, w_2, \ldots, w_n)^T \neq \mathbf{0}
\]
we have
\begin{equation*}
    \mathbf{w}^T A \mathbf{w} = a(w,w) > 0.
\end{equation*}
It follows that $A$ is positive definite, making it symmetric positive definite (SPD). Additionally, through the coercive property of $a$ in combination with the Lax-Milgram theorem we get that both the continuous and discrete weak formulations \cref{prob:elliptic_problem_weak,prob:elliptic_problem_discretized} are well-posed and have unique solutions.

Apart from possibly complex domains $\Omega$, a major obstacle in solving the linear system $A\mathbf{u} = \mathbf{b}$ from \cref{prob:elliptic_problem_discretized}, comes from its high-contrast coefficient $\mathcal{C}$, which requires a broad range of element sizes $|\tau|$ in the triangulation $\mathcal{T}$ to fully resolve. As a result, the number of DOFs $n = |\mathcal{N}|$ can be very large, leading to a system matrix $A$ that is large and sparse. This makes direct methods like Gaussian elimination, LU- or Cholesky decomposition impractical, as they require storing the entire matrix in memory and generally have complexity $\mathcal{O}(n^3)$.

Though $A$ is large and sparse, it \textit{is} SPD. Therefore, the linear system $A\mathbf{u} = \mathbf{b}$ can be solved using the Conjugate Gradient method (CG). CG requires only the ability to compute matrix-vector products with $A$ (complexity $\mathcal{O}(n)$ for sparse matrices) and does not require storing the entire matrix. Being an iterative method, CG produces a sequence of approximations $\mathbf{u}_i, \ i = 1,\dots,m$ to the solution $\mathbf{u}$ and stops when some convergence criterion depending on a desired tolerance $\epsilon$ is met. This means that CG's complexity is given by $\mathcal{O}(mn)$.

Hence, the number of iterations $m$ required for convergence is a crucial factor in the performance of CG. The key subject of \cref{sec:cg_convergence} is to analyze the convergence of CG and how it depends on the properties of the system matrix $A$. In particular, we will show that $m$ is related to the distribution of the eigenvalues of $A$. For instance, in exact arithmetic $m$ is bounded by the number of distinct eigenvalues of $A$, say $k$, from which follows that CG's complexity is given by $\mathcal{O}(kn)$. In general, we can derive, using a well-known bound on CG's convergence rate discussed in \cref{th:cg_convergence_rate_bound}, an explicit expression for CG's complexity
\begin{equation}
  \mathcal{O}\left(\sqrt{\kappa(A)}\log\left(\frac{2}{\epsilon}\right)n\right),
  \label{eq:cg_complexity}
\end{equation}
where $\kappa(A)$ is the condition number of $A$. Comparing \cref{eq:cg_complexity} with the complexity of direct methods, we see that CG is much more efficient for large sparse SPD matrices like $A$. 

However, the difficulty of allowing for a high-contrast coefficient $\mathcal{C}$ and, for instance, complex domains resides in that the condition number $\kappa(A)$ can be very large, which in turn increases CG's iteration count and complexity. Accounting for the high-contrast coefficient $\mathcal{C}$ concerns the construction of robust \textit{coarse spaces}, some examples of which are given in \cref{ch:literature}. On the other hand, handling of complex domains can be done using \textit{domain decomposition methods} and this is the topic of \cref{sec:schwarz_methods}. 

The particular implementation of domain decomposition method and coarse space results in a preconditioner matrix $M\in\mathbb{R}^{n \times n}$, which is used to transform the system $A\mathbf{u} = \mathbf{b}$ into a new system $M^{-1}A\mathbf{u} = M^{-1}\mathbf{b}$ with a (hopefully) smaller condition number. The preconditioned CG method (PCG), described in \cref{sec:cg_preconditioning}, is then used to solve the transformed system. Consequently, using the equivalent of the CG complexity bound \cref{eq:cg_complexity} for PCG, we can determine the performance of PCG with the preconditioner $M$ as
\begin{equation}
  \mathcal{O}\left(\sqrt{\kappa(M^{-1}A)}\log\left(\frac{2}{\epsilon}\right)n\right).
  \label{eq:pcg_complexity}
\end{equation}

This thesis seeks to review the applicability of the bound in \cref{eq:pcg_complexity} to problems like \cref{prob:elliptic_problem}. The bound relies on an overestimation of the actual number of iterations $m$ required for convergence and overstates the role of the condition number $\kappa(M^{-1}A)$ in determining the convergence rate of CG. We will see in \cref{sec:cg_eigenvalue_distribution} that the actual number of iterations $m$ is much smaller than the classical bound that \cref{eq:pcg_complexity} relies on and that the condition number $\kappa(M^{-1}A)$ is not the only factor influencing the convergence rate of CG. 

The main research question in this work is as follows:
\begin{researchq} \label{rq:main}
    \par
    How can we sharpen the CG iteration bound for Schwarz-preconditioned high-contrast heterogeneous scalar-elliptic problems beyond the classical condition number-based bound?
\end{researchq}
For instance, in \cite{ams_coarse_space_comp_study_Alves2024}, a two-level Schwarz preconditioner with either one of the AMS and GDSW coarse spaces significantly outperforms the same preconditioner with RGDSW coarse space, despite all three preconditioned systems having similar condition numbers. The key differences appear in their spectral gap and cluster width, highlighting the need for further investigation into spectral properties beyond the condition number.

\begin{subsidiaryq} \label{rq:subsidiaries}
    To answer the main research question, we address the following subsidiary questions:
    \setlength\itemindent{1in}
    \begin{enumerate}[label=\textbf{Q\arabic*}, ref=\textbf{Q\arabic*}, leftmargin=1cm]
        \item\label{rq:subsidiary:heuristic} Given a certain eigenspectrum, can we construct a bound that is sharper than the classical condition number-based bound?
        \item\label{rq:subsidiary:measures} How does the number of CG iterations necessary for convergence of high-contrast heterogeneous problems depend on spectral characteristics other than the condition number?
        \item\label{rq:subsidiary:preconditioners} Can we obtain a priori estimates for the number of iterations necessary for convergence of   a PCG method with Schwarz-like preconditioners?
    \end{enumerate}
\end{subsidiaryq}

This research has great practical importance for the selection of the most efficient preconditioner for a given high-contrast problem. The condition number does not suffice to differentiate between preconditioners, as outlined in \cite{ams_coarse_space_comp_study_Alves2024}. Thus, having the ability to differentiate preconditioners based on spectral characteristics from, for instance, their approximate eigenspectra would improve the selection process.

On top of that, having sharper bounds for (P)CG methods allows for more efficient allocation of computational resources, as it allows for a more accurate estimate of the number of iterations necessary for convergence. This is particularly important in high-performance computing environments, where the cost of each iteration can be significant.

As mentioned above, the computational complexity of (P)CG methods is given in \cref{eq:cg_complexity,eq:pcg_complexity}. If we can find a bound that scales better with the other spectral characteristics, we can possibly show that (P)CG methods with Schwarz-like preconditioners are applicable to a wider range of high-contrast problems than previously thought. This would open up new avenues for research and applications in the field of numerical analysis and scientific computing.

Finding sharper bounds than the classical condition number-based bound is a non-trivial task. The main challenge lies in the fact that the condition number is a measure of the worst-case scenario, while we are interested in the average-case behavior of the (P)CG method. This requires a more nuanced understanding of the eigenspectrum and its impact on the convergence of the method.

Assuming we have some expression for a sharper bound, the following challenge then lies in obtaining a priori estimates for the spectrum of the preconditioned system. The literature does provide condition number estimates for various Schwarz preconditioners. For instance, in the simple cases of the additive Schwarz preconditioner with either a \ref{ASM_coarse_space:nicolaides} or \ref{ASM_coarse_space:local_eigenfunctions} an a priori estimate for the condition number is given by \cref{eq:two_level_ASM_condition_number} in combination with either \cref{eq:c0_nicolaides} or \cref{eq:c0_local_eigenfunctions}, respectively. The same can be said for the MsFEM and ACMS preconditioners, as is seen in \cref{sec:tailored_coarse_spaces}.

However, these estimates are not always sharp, and they do not provide information about the spectral gap or cluster width of the preconditioned system. So, the challenge remains; how can we obtain a priori estimates of the spectral characteristics necessary for the sharp bound?

Fortunately, we can always obtain a posteriori estimates for the spectrum of the preconditioned system, as is done in \cref{ch:results}. However, this requires the computation of the eigenspectrum of the preconditioned system, which can be computationally expensive. This is where the use of iterative methods such as (P)CG comes in handy, as they allow us to compute the eigenspectrum during the solution of the linear system.

This thesis is organized as follows. In \fullref{ch:background}, the mathematical background of the CG method and Schwarz methods is introduced. \fullref{ch:literature} reviews related work on coarse spaces and improved CG iteration bounds. In \fullref{ch:methods}, we expand on the available literature and ultimately derive two novel algorithms for a sharpened CG iteration bounds designed for high-contrast problems. The performance and practical applicability of the sharpened CG iteration bounds are then evaluated in \fullref{ch:results}. Finally, \fullref{ch:conclusion} summarizes the key insights and discusses directions for future research.